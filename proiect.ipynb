{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e2de84",
   "metadata": {},
   "source": [
    "# 1) Data inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11efa598",
   "metadata": {},
   "source": [
    "### 1-Import Libraries and Load Dataset\n",
    "\n",
    "#### We import the pandas library for data manipulation.\n",
    "#### We read the CSV file into a DataFrame called df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cd08309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv(\"housing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc99441",
   "metadata": {},
   "source": [
    "### 2-Preview Data\n",
    "#### df.head() shows the first 5 rows to quickly check the data.\n",
    "#### df.tail() shows the last 5 rows to ensure the data loaded correctly.\n",
    "#### df.info() provides column names, data types, and non-null counts.\n",
    "#### df.shape returns the number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"====First 5 Rows====\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "print(\"====Last 5 Rows====\")\n",
    "print(df.tail())\n",
    "\n",
    "\n",
    "print(df.info())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43070e0a",
   "metadata": {},
   "source": [
    "### 3-Check Missing Values & Check Duplicated Data\n",
    "#### df.isna().sum() calculates the number of missing values in each column.\n",
    "#### Helps us identify which columns need cleaning or imputation.\n",
    "#### df.duplicated().sum() counts duplicate rows in the dataset.\n",
    "#### Duplicate data can affect analysis and should be handled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296df2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing Values:\\n\")\n",
    "print(df.isna().sum(),\"\\n\")\n",
    "\n",
    "print(\"Duplicated Data:\",df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006b63fe",
   "metadata": {},
   "source": [
    "### 4-Explore Categorical Columns\n",
    "#### Selects columns with object type (categorical data).\n",
    "#### value_counts().head(10) shows the 10 most frequent values for each categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11371090",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = df.select_dtypes(include=['object'])\n",
    "for col in object_cols:\n",
    "    print(col)\n",
    "    print(df[col].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5588a82",
   "metadata": {},
   "source": [
    "### 5-Unique Values per Column\n",
    "#### nunique() returns the number of unique values in each column.\n",
    "#### Helps understand diversity of values and detect potential categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"Columns:{col}\")\n",
    "    print(\"Unique:\",df[col].nunique())\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e60a23",
   "metadata": {},
   "source": [
    "### 6-Descriptive Statistics for Numeric Columns\n",
    "#### df.describe() provides count, mean, std, min, max, and quartiles for numeric columns.\n",
    "#### Useful for understanding the distribution of numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f03f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_col = df.select_dtypes(include=['float64','int64'])\n",
    "print(numeric_col.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ffe8dd",
   "metadata": {},
   "source": [
    "# 2) Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34df8f",
   "metadata": {},
   "source": [
    "### 1-Import Libraries and Load Dataset\n",
    "#### Import libraries for data analysis and visualization.\n",
    "#### Load the housing dataset into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5007103",
   "metadata": {},
   "source": [
    "### 2-Initial Data Exploration\n",
    "#### Check missing values, duplicates, and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb701e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = ['longitude','latitude','housing_median_age','total_rooms','total_bedrooms','population',\n",
    "            'households','median_income','median_house_value']\n",
    "\n",
    "print(\"==== DATA BEFORE CLEANING ====\")\n",
    "print(\"\\nNull values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "print(\"\\nNumeric summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb617b",
   "metadata": {},
   "source": [
    "### 3-Outlier Detection Function\n",
    "#### Define a function to count outliers using IQR.\n",
    "#### Print outlier counts before cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca49985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = series[(series < lower_bound) | (series > upper_bound)]\n",
    "    return len(outliers)\n",
    "\n",
    "print(\"===== OUTLIERS BEFORE CLEANING =====\")\n",
    "for col in columns_to_plot:\n",
    "    count = detect_outliers_iqr(df[col])\n",
    "    print(f\"{col}: {count} outliers\")\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ff506",
   "metadata": {},
   "source": [
    "### 4-Visualize Outliers Before Cleaning\n",
    "#### Boxplots show distribution and outliers visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58448a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15,12))\n",
    "for ax, col in zip(axes.flatten(), columns_to_plot):\n",
    "    sns.boxplot(x=df[col], ax=ax)\n",
    "    ax.set_title(f'{col} (Before Cleaning)')\n",
    "    \n",
    "plt.tight_layout(pad=5.0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18006e6e",
   "metadata": {},
   "source": [
    "### 5- Clean Data\n",
    "#### Fill missing total_bedrooms with mean.\n",
    "#### Clip numeric columns to remove extreme outliers.\n",
    "#### Display stats after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_bedrooms'] = df['total_bedrooms'].fillna(df['total_bedrooms'].mean())\n",
    "\n",
    "num_cols_clean = ['longitude','latitude','housing_median_age','total_rooms','total_bedrooms','population',\n",
    "            'households','median_income','median_house_value']\n",
    "\n",
    "for col in num_cols_clean:\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5*iqr\n",
    "    upper = q3 + 1.5*iqr\n",
    "  \n",
    "    df[col] = df[col].clip(lower=lower, upper=upper)\n",
    "\n",
    "print(\"\\n===== DATA AFTER CLEANING =====\")\n",
    "print(\"\\nNull values per column:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())\n",
    "print(\"\\nNumeric summary (cleaned columns):\")\n",
    "print(df[num_cols_clean].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ffba69",
   "metadata": {},
   "source": [
    "### 6-Visualize After Cleaning & Save Dataset\n",
    "#### Visualize cleaned data with boxplots.\n",
    "#### Print remaining outlier counts.\n",
    "#### Save cleaned DataFrame to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15,12))\n",
    "for ax, col in zip(axes.flatten(), num_cols_clean):\n",
    "    sns.boxplot(x=df[col], ax=ax)\n",
    "    ax.set_title(f'{col} (After Cleaning)')\n",
    "plt.tight_layout(pad=5.0)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n===== FINAL OUTLIERS COUNT =====\")\n",
    "for col in num_cols_clean:\n",
    "    outliers = detect_outliers_iqr(df[col])\n",
    "    print(f\"{col}: {outliers} outliers\")\n",
    "\n",
    "\n",
    "df.to_csv('cleaned_housing.csv', index=False)\n",
    "print(\"\\n===== CLEANED DATA SAVED SUCCESSFULLY =====\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951b45b8",
   "metadata": {},
   "source": [
    "# 3) Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8043c1f4",
   "metadata": {},
   "source": [
    "### 1-Import Libraries and Load Dataset\n",
    "#### Loading the cleaned dataset ensures we work with ready-to-use data.\n",
    "#### Knowing the target column (median_house_value) is crucial for any predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c99229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('cleaned_housing.csv')\n",
    "print(\"Number of rows:\", df.shape[0])\n",
    "print(\"Number of columns:\", df.shape[1])\n",
    "print(\"Target column:\", \"median_house_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ecb29d",
   "metadata": {},
   "source": [
    "### 2-Distribution of Target Variable\n",
    "#### Visualizing the target helps understand its distribution.\n",
    "#### Important for choosing model type (e.g., regression) and detecting skewness that may require transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['median_house_value'], bins=50, color='purple')\n",
    "plt.title(\"Histogram of Median House Value\")\n",
    "plt.xlabel(\"Median House Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53610b1d",
   "metadata": {},
   "source": [
    "### 3-Correlation Heatmap\n",
    "#### Shows relationships between features and the target.\n",
    "#### Helps identify strong predictors for the model and potential multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = df.select_dtypes(include=['int64', 'float64'])\n",
    "corr_matrix = numeric_features.corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c542134",
   "metadata": {},
   "source": [
    "### 4-Median Income vs Target\n",
    "#### Directly visualizes how median_income influences the target.\n",
    "#### Strong correlation here indicates median_income is a key predictor for housing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2c5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['median_income'], df['median_house_value'], alpha=0.5,color=\"#F0749B\")\n",
    "plt.title(\"Median Income vs Median House Value\")\n",
    "plt.xlabel(\"Median Income\")\n",
    "plt.ylabel(\"Median House Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316e49a",
   "metadata": {},
   "source": [
    "### 5-Categorical Feature vs Target\n",
    "#### Shows how categorical features like ocean_proximity affect the target.\n",
    "#### Useful for feature encoding and understanding impact on predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ec453",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='ocean_proximity', y='median_house_value', data=df,color=\"teal\")\n",
    "plt.title(\"Ocean Proximity vs Median House Value\")\n",
    "plt.xlabel(\"Ocean Proximity\")\n",
    "plt.ylabel(\"Median House Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d1a98",
   "metadata": {},
   "source": [
    "### 6-Geographical Visualization\n",
    "#### Visualizes how location (longitude & latitude) influences house value.\n",
    "#### Useful for models to capture spatial patterns or for feature engineering (e.g., clustering by location)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0e2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(df['longitude'], df['latitude'], c=df['median_house_value'], cmap='viridis', alpha=0.5)\n",
    "plt.colorbar(label='Median House Value')\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.title(\"Location vs Median House Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777f09d7",
   "metadata": {},
   "source": [
    "# 4) prediction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b72a168",
   "metadata": {},
   "source": [
    "### 1-Import Libraries\n",
    "#### This cell imports all necessary libraries for data handling, preprocessing, modeling, and evaluation.\n",
    "#### It includes pandas, numpy, scikit-learn modules, matplotlib, and XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da367ba3",
   "metadata": {},
   "source": [
    "### 2-Load Dataset \n",
    "#### -Load your housing dataset.\n",
    "#### -y is the target (what we want to predict).\n",
    "#### -X contains all features.\n",
    "#### -Separate features into numeric and categorical for preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccddd506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_housing.csv\")\n",
    "\n",
    "y = df[\"median_house_value\"]\n",
    "\n",
    "numeric_features = [\n",
    "    \"median_income\", \"longitude\", \"latitude\", \"housing_median_age\",\n",
    "    \"total_rooms\", \"total_bedrooms\", \"population\", \"households\"\n",
    "]\n",
    "categorical_features = [\"ocean_proximity\"]\n",
    "\n",
    "X = df[numeric_features + categorical_features]\n",
    "\n",
    "print(X.shape)\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9754457c",
   "metadata": {},
   "source": [
    "### 3-Preprocessing\n",
    "#### StandardScaler ‚Üí scales numeric values to a standard range.\n",
    "#### OneHotEncoder ‚Üí converts categorical features into numbers.\n",
    "#### ColumnTransformer ‚Üí applies transformations to the correct columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aced36",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer=Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocessor= ColumnTransformer(\n",
    "    transformers=[(\"num\", numeric_transformer, numeric_features),(\"cat\", categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946dcf95",
   "metadata": {},
   "source": [
    "### 4-Split Data\n",
    "#### Split data into Train (60%), Validation (20%), and Test (20%) sets.\n",
    "#### Validation is used for tuning models, Test is for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e247ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d7e63",
   "metadata": {},
   "source": [
    "### 5-Model Evaluation Function\n",
    "#### Fits a model and calculates RMSE, MAE, R¬≤ for train, validation, and test sets.\n",
    "#### Returns a dictionary of metrics for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_val, y_cv, X_test,y_test ):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = {\n",
    "        \"train\": model.predict(X_train),\n",
    "        \"val\": model.predict(X_val),\n",
    "        \"test\": model.predict(X_test)\n",
    "    }\n",
    "    \n",
    "    metrics = {}\n",
    "    for k in preds:\n",
    "        metrics[k] = {\n",
    "            \"rmse\": np.sqrt(mean_squared_error(eval(f\"y_{k}\"), preds[k])),\n",
    "            \"mae\": mean_absolute_error(eval(f\"y_{k}\"), preds[k]),\n",
    "            \"r2\": r2_score(eval(f\"y_{k}\"), preds[k])\n",
    "        }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9f1c0",
   "metadata": {},
   "source": [
    "## 6-Hyperparameter Tuning Function\n",
    "#### Function for tuning a hyperparameter for any model.\n",
    "#### Plots train vs validation RMSE to visualize bias-variance tradeoff.\n",
    "#### Returns the best model with its metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d5d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tune_model(model_name, model_class, param_name, param_values, extra_params=None):\n",
    "    train_rmse, val_rmse = [], []\n",
    "    \n",
    "    for val in param_values:\n",
    "        params = {param_name: val}\n",
    "        if extra_params:\n",
    "            params.update(extra_params)\n",
    "        \n",
    "        model = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (model_name, model_class(**params))\n",
    "        ])\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_cv)\n",
    "        \n",
    "        train_rmse.append(np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "        val_rmse.append(np.sqrt(mean_squared_error(y_cv, y_val_pred)))\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(param_values, train_rmse, marker='o', label=\"Train RMSE\")\n",
    "    plt.plot(param_values, val_rmse, marker='o', label=\"Validation RMSE\")\n",
    "    plt.xscale(\"log\" if param_name==\"alpha\" else \"linear\")  \n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(f\"Bias-Variance Tradeoff ({model_name})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    best_idx = np.argmin(val_rmse)\n",
    "    best_param = param_values[best_idx]\n",
    "    \n",
    "    print(f\"Best {param_name}: {best_param}\")\n",
    "    print(f\"Train RMSE: {train_rmse[best_idx]:.2f}\")\n",
    "    print(f\"Validation RMSE: {val_rmse[best_idx]:.2f}\")\n",
    "    \n",
    "\n",
    "    best_model = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (model_name, model_class(**{param_name: best_param}))\n",
    "    ])\n",
    "    \n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    def evaluate(X, y):\n",
    "        pred = best_model.predict(X)\n",
    "        rmse = np.sqrt(mean_squared_error(y, pred))\n",
    "        mae = mean_absolute_error(y, pred)\n",
    "        r2 = r2_score(y, pred)\n",
    "        return rmse, mae, r2\n",
    "    \n",
    "    train_metrics = evaluate(X_train, y_train)\n",
    "    val_metrics = evaluate(X_cv, y_cv)\n",
    "    test_metrics = evaluate(X_test, y_test)\n",
    "    \n",
    "    print(\"\\nFinal Evaluation:\")\n",
    "    print(f\"Train -> RMSE: {train_metrics[0]:.2f}, MAE: {train_metrics[1]:.2f}, R¬≤: {train_metrics[2]:.4f}\")\n",
    "    print(f\"Val   -> RMSE: {val_metrics[0]:.2f}, MAE: {val_metrics[1]:.2f}, R¬≤: {val_metrics[2]:.4f}\")\n",
    "    print(f\"Test  -> RMSE: {test_metrics[0]:.2f}, MAE: {test_metrics[1]:.2f}, R¬≤: {test_metrics[2]:.4f}\")\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    return best_model, train_metrics, val_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647d9338",
   "metadata": {},
   "source": [
    "### 7- Train & Tune Models\n",
    "#### Tune 4 different models: Ridge, Decision Tree, Random Forest, XGBoost.\n",
    "#### Finds best hyperparameters and evaluates metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea36e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear reg\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "best_model_ridge, ridge_train, ridge_val, ridge_test = tune_model(\n",
    "    model_name=\"ridge\",\n",
    "    model_class=Ridge,\n",
    "    param_name=\"alpha\",\n",
    "    param_values=alphas\n",
    ")\n",
    "\n",
    "# decision tree\n",
    "depths = [2, 4, 6, 8, 10]\n",
    "best_model_tree, tree_train, tree_val, tree_test = tune_model(\n",
    "    model_name=\"tree\",\n",
    "    model_class=DecisionTreeRegressor,\n",
    "    param_name=\"max_depth\",\n",
    "    param_values=depths\n",
    ")\n",
    "#random forest \n",
    "depths = [5, 10, 15, 20,25]\n",
    "\n",
    "best_model_rf, rf_train, rf_val, rf_test = tune_model(\n",
    "    model_name=\"rf\",model_class=RandomForestRegressor, param_name=\"max_depth\",param_values=depths,\n",
    "    extra_params={\"random_state\": 42, \"n_jobs\": -1})\n",
    "\n",
    "# xgboost\n",
    "xgb_depths = [3, 5, 7, 9]\n",
    "best_model_xgb, xgb_train_rmse, xgb_val_rmse, xgb_test_rmse = tune_model(model_name=\"xgb\",model_class=XGBRegressor,\n",
    "    param_name=\"max_depth\",param_values=xgb_depths,\n",
    "    extra_params={\"n_estimators\":6000,\"learning_rate\":0.01,\"min_child_weight\":6,\"subsample\":0.7,\n",
    "        \"colsample_bytree\":0.85,\"reg_alpha\":0.5,\"reg_lambda\":3,\"objective\":\"reg:squarederror\",\"random_state\":42,\"n_jobs\":-1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ca683",
   "metadata": {},
   "source": [
    "## 8-Compare Models\n",
    "#### Summarize all metrics in a dataframe for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Ridge\", \"Decision Tree\", \"Random Forest\", \"XGBoost\"],\n",
    "    \n",
    "    \"Train RMSE\": [ridge_train[0], tree_train[0], rf_train[0], xgb_train_rmse[0]],\n",
    "    \"Val RMSE\":   [ridge_val[0], tree_val[0], rf_val[0], xgb_val_rmse[0]],\n",
    "    \"Test RMSE\":  [ridge_test[0], tree_test[0], rf_test[0], xgb_test_rmse[0]],\n",
    "    \n",
    "    \"Train MAE\": [ridge_train[1], tree_train[1], rf_train[1], xgb_train_rmse[1]],\n",
    "    \"Val MAE\":   [ridge_val[1], tree_val[1], rf_val[1], xgb_val_rmse[1]],\n",
    "    \"Test MAE\":  [ridge_test[1], tree_test[1], rf_test[1], xgb_test_rmse[1]],\n",
    "    \n",
    "    \"Train R2\": [ridge_train[2], tree_train[2], rf_train[2], xgb_train_rmse[2]],\n",
    "    \"Val R2\":   [ridge_val[2], tree_val[2], rf_val[2], xgb_val_rmse[2]],\n",
    "    \"Test R2\":  [ridge_test[2], tree_test[2], rf_test[2], xgb_test_rmse[2]],\n",
    "})\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2859facc",
   "metadata": {},
   "source": [
    "### 9-Visualize Model Performance\n",
    "#### Compare Train, Validation, Test RMSE visually.\n",
    "#### Compare Train, Validation, Test MAE visually.\n",
    "#### Compare Train, Validation, Test R¬≤ visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cd3de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Ridge\", \"Decision Tree\", \"Random Forest\", \"XGBoost\"]\n",
    "\n",
    "train_rmse_list = results[\"Train RMSE\"].values\n",
    "val_rmse_list   = results[\"Val RMSE\"].values\n",
    "test_rmse_list  = results[\"Test RMSE\"].values\n",
    "\n",
    "train_mae_list = results[\"Train MAE\"].values\n",
    "val_mae_list   = results[\"Val MAE\"].values\n",
    "test_mae_list  = results[\"Test MAE\"].values\n",
    "\n",
    "train_r2_list = results[\"Train R2\"].values\n",
    "val_r2_list   = results[\"Val R2\"].values\n",
    "test_r2_list  = results[\"Test R2\"].values\n",
    "\n",
    "# -------------------- RMSE Comparison --------------------\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(x - width, train_rmse_list, width, label='Train RMSE', color=\"#7c35ae\")\n",
    "plt.bar(x, val_rmse_list, width, label='Validation RMSE', color='#9b59b6')\n",
    "plt.bar(x + width, test_rmse_list, width, label='Test RMSE', color=\"#c37bdf\")\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Comparison of Models Performance (RMSE)')\n",
    "plt.xticks(x, models)\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# -------------------- MAE Comparison --------------------\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(x - width, train_mae_list, width, label='Train MAE', color=\"#27ae60\")\n",
    "plt.bar(x, val_mae_list, width, label='Validation MAE', color=\"#2ecc71\")\n",
    "plt.bar(x + width, test_mae_list, width, label='Test MAE', color=\"#58d68d\")\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Comparison of Models Performance (MAE)')\n",
    "plt.xticks(x, models)\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# -------------------- R¬≤ Comparison --------------------\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(x - width, train_r2_list, width, label='Train R¬≤', color=\"#37abb1\")\n",
    "plt.bar(x, val_r2_list, width, label='Validation R¬≤', color=\"#52fbea\")\n",
    "plt.bar(x + width, test_r2_list, width, label='Test R¬≤', color=\"#8dfae4\")\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('R¬≤')\n",
    "plt.title('Comparison of Models Performance (R¬≤)')\n",
    "plt.xticks(x, models)\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39301b84",
   "metadata": {},
   "source": [
    "## 10- Scatter Plot \n",
    "#### To compare the actual house prices (y_test) with the predicted prices from each of your 4 models.\n",
    "#### This helps you see if the predictions are close to reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_objs = [best_model_ridge, best_model_tree, best_model_rf, best_model_xgb]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "for i, model in enumerate(model_objs):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5, color='#6a0dad')\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.xlabel(\"Actual Price\")\n",
    "    plt.ylabel(\"Predicted Price\")\n",
    "    plt.title(f\"{models[i]}: Actual vs Predicted\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190af33c",
   "metadata": {},
   "source": [
    "### 11- Select Best Model\n",
    "#### Pick the model with lowest validation RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1bcbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_val_rmse = val_rmse_list  \n",
    "\n",
    "best_idx = int(np.argmin(all_val_rmse))  \n",
    "best_model_name = models[best_idx]\n",
    "best_val_rmse_value = all_val_rmse[best_idx]\n",
    "\n",
    "model_dict = {\n",
    "    \"Ridge\": best_model_ridge,\n",
    "    \"Decision Tree\": best_model_tree,\n",
    "    \"Random Forest\": best_model_rf,\n",
    "    \"XGBoost\": best_model_xgb\n",
    "}\n",
    "\n",
    "best_model = model_dict[best_model_name]\n",
    "\n",
    "print(\"\\n\" + \"*\"*95)\n",
    "print(f\"üéâ‚ú® Congratulations! The best model is '{best_model_name}' with a Validation RMSE of {best_val_rmse_value:.2f}! ‚ú®üéâ\")\n",
    "print(\"*\"*95 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff85e4ce",
   "metadata": {},
   "source": [
    "## 12-Interactive House Price Prediction\n",
    "### Allow the user to input house details and predict price using best XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"\\n‚ú® Hey there! ‚ú®\")\n",
    "print(\"Let‚Äôs try something fun üöÄ\")\n",
    "print(\"Enter your own house details and let the model predict the price for you üè°üí∞\\n\")\n",
    "\n",
    "def safe_float(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            return float(input(prompt))\n",
    "        except ValueError:\n",
    "            print(\"‚ùå Please enter a valid number!\")\n",
    "\n",
    "# Ocean proximity choices\n",
    "ocean_menu = {\n",
    "    1: \"<1H OCEAN\",\n",
    "    2: \"INLAND\",\n",
    "    3: \"NEAR BAY\",\n",
    "    4: \"ISLAND\",\n",
    "    5: \"NEAR OCEAN\"\n",
    "}\n",
    "\n",
    "print(\"\\nChoose Ocean Proximity:\")\n",
    "for k, v in ocean_menu.items():\n",
    "    print(f\"{k} - {v}\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        choice = int(input(\"Enter choice (1-5): \"))\n",
    "        if choice in ocean_menu:\n",
    "            ocean_input = ocean_menu[choice]\n",
    "            break\n",
    "        else:\n",
    "            print(\"‚ùå Choose a number between 1 and 5\")\n",
    "    except ValueError:\n",
    "        print(\"‚ùå Enter numbers only!\")\n",
    "\n",
    "# Collect user input\n",
    "user_data = {\n",
    "    \"longitude\": safe_float(\"Longitude: \"),\n",
    "    \"latitude\": safe_float(\"Latitude: \"),\n",
    "    \"housing_median_age\": safe_float(\"Housing Median Age: \"),\n",
    "    \"total_rooms\": safe_float(\"Total Rooms: \"),\n",
    "    \"total_bedrooms\": safe_float(\"Total Bedrooms: \"),\n",
    "    \"population\": safe_float(\"Population: \"),\n",
    "    \"households\": safe_float(\"Households: \"),\n",
    "    \"median_income\": safe_float(\"Median Income: \"),\n",
    "    \"ocean_proximity\": ocean_input\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "user_df = pd.DataFrame([user_data])\n",
    "\n",
    "# --- Use the full pipeline with best_model ---\n",
    "# best_model = pipeline with preprocessor + best selected model\n",
    "predicted_price = best_model.predict(user_df)[0]\n",
    "\n",
    "print(\"\\nüè† Predicted House Price:\")\n",
    "print(f\"üíµ ${predicted_price:,.2f}\")\n",
    "\n",
    "# Optional: compare to actual price if known\n",
    "user_real_price = float(input(\"\\nIf you know the real price, enter it (or 0 to skip): \"))\n",
    "if user_real_price > 0:\n",
    "    error = abs(user_real_price - predicted_price)\n",
    "    accuracy = 1 - (error / user_real_price)\n",
    "    print(f\"\\n Absolute Error: ${error:,.2f}\")\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "    print(\"\\nüéâ Prediction completed successfully! \")\n",
    "else:\n",
    "    print(\"\\nüéâ Prediction completed successfully! Try changing values to see new results üöÄ\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
